# 深度排序模型在淘宝直播的演进与应用

来自 淘宝-纪志辉



![image-20210204210547896](https://i.loli.net/2021/02/04/3VNjOat9qn8SPf4.png)



## DBMTL1.0 - 目标时序建模  

![image-20210204210930766](https://i.loli.net/2021/02/04/va5ZAptfuq723mc.png)

 其中多目标单独建模 **忽略了 目标之间的信息共享**（时长和点击的关系）

**feature-target**（底层信息共享） 和 **target-target**(需要考虑目标之间的因果关联)

腾讯- PLE 



**贝叶斯网络？**（条件关系么？ ） 就是不同的目标是有条件顺序的， 如只有在点击之后 才会有评论，时长之类的信息 

**Deep Bayesian Multi-task Learning 1.0 (2018)**  

![image-20210204211741448](https://i.loli.net/2021/02/04/toNHJAGc5DbSd94.png)

贝叶斯层（target-target）：通过前序目标的输出作为后序目标的输入刻画概率转移关系  

目前的参数还是主要是手动调整 



## DBMTL 2.0 - MMOE（feature-target 变为 soft）

![image-20210204213827419](https://i.loli.net/2021/02/04/5mRa6BkVSQGeLlI.png)

主要就是 由hard parameter sharing -》 soft parameter sharing 即 mmoe （multi-gate mixture of experts）

Gate设计：Linear Transform + Softmax  

好处： 灵活地**自适应学习不同任务**对共享网络的选择   + 增加其他目标并**不会增加网络的复杂度**  



**对比mmoe 有很大的提升** 



## DBMTL 3.0 - 多场景多任务

![image-20210205074257593](https://i.loli.net/2021/02/05/6eGWLmDOAct5QZj.png)

多场景下的 多任务学习 （新场景 数据量小 其实业务相差不大）

此时： 

**特征**， 既有自己单独特有的特征， 也有共享的特征

中间层，mmoe 多任务-》 多场景 多任务



不同时间段 可以让目标有不同的侧重 （日常和大促的不同场景）（双十一重大提升）



## DMR 1.0 召回匹配建模

![image-20210205075300392](https://i.loli.net/2021/02/05/9kLY8vz5XD1dJuH.png)



尝试在网络上层来刻画**user-item显示匹配关系**

增加了一个 match-tower 来刻画 user-item的相关性 （各自做embedding之后做点积  fc， 得到**logits**）

猜想收益原因： 可能底层特征共享不够好 留给网络优化空间大 

![image-20210205075452825](https://i.loli.net/2021/02/05/cBNRy2m6YFq9Z7e.png)



## DMR 2.0  - 两阶段召回匹配

### 召回预训练

学习用户在不同召回（不同模态）下的表征（embedding）

如何刻画用户在不同召回（多模态）下的表征：

![image-20210205080454462](https://i.loli.net/2021/02/05/xOpPqSVXeWhzfH7.png)

![image-20210205080942214](https://i.loli.net/2021/02/05/MiCQpI7ZV9ok1Oy.png)

U2A： 用户行为历史

U2A2A - 用户行为历史的协同  是 先做的item-cf 得到后面的A2A 之后再join U2A

最终得到用户在不同模态下的表征以及主播表征 



### 两阶段召回匹配

得到多模态表征之后 ， 

![image-20210205081431412](https://i.loli.net/2021/02/05/GCKAxWPD8nFQRXN.png)

![image-20210205081506862](https://i.loli.net/2021/02/05/Ufe1AkwHgm2Y8l7.png)



在match-tower中，多路召回（多模态）预训练向量 & 点积   和本次训练的share user embedding 做sum-pooling mean-pooling

rank tower: 直接输入 + cross & MLP  



缺点： DMR 2.0 ：两阶段链路上下游依赖性强、不易维护、通用性差  

尝试后续直接 学习end2end的方式



上述都是列表页的排序建模， 淘宝在进入直播间之后是可以上下滑动 进行直播间切换的 

全屏页上下滑（RUI） refer-user-item



## RUI Ranking 1.0  

refer是当前直播间，下滑重要的是 refer相关性有关 

![image-20210205085809312](https://i.loli.net/2021/02/05/y79RwiQYaO1LfEl.png)

视频播放目标:

![image-20210205085751712](https://i.loli.net/2021/02/05/nA7vorVeYzZCUBF.png)



## RUI Ranking 2.0  

1.0 没有突出refer的重要性与差异 在R2Itower中单独刻画 refer和item之间的关系 

![image-20210205085853962](https://i.loli.net/2021/02/05/5Ahj2dlrykuQmxM.png)



## RUI Ranking 3.0  

需要加入 用户和当前refer的关系 确定用户是否喜欢当前refer 

在 match-net 加入 U2R ， R2I， U2I， 3个独立的tower， 方法： u2r * r2i + u2i  

![image-20210205090509574](https://i.loli.net/2021/02/05/HXP4qatTj7ZhIKl.png)