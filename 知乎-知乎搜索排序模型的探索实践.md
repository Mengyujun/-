# 知乎搜索排序模型的探索实践

来自： 王瑞欣- 知乎搜索算法团队  



大纲： 

- 多目标排序
- Unbias LTR
- Context Aware
- End2End
- Session Aware



其发展历程：

![image-20210203160533653](https://i.loli.net/2021/02/03/n1gymTI5RiFdlxG.png)

**搜索架构：** 

![image-20210203160510459](https://i.loli.net/2021/02/03/v2L6kubP3zy7MtJ.png)

迁移DNN原因：
• 数据量变大可以支持更高的模型复杂度
• 支持最新的研究成果，比如多目标排序  



## 排序模型

![image-20210203160740991](https://i.loli.net/2021/02/03/QxOAk2KpGrzN5Su.png)

左侧是unbias部分



## 多目标排序

由单一的预估ctr 增加： **阅读时长**，**点赞**，收藏，**关注**， 分享， 评论 等多个用户留存指标

其中  加粗的是 主要目标，与用户留存关系大



第一版： 共享底层

![image-20210203171421145](https://i.loli.net/2021/02/04/Sm1kwsV5Y8WZMeg.png)

对于时长这类的目标， 要做log转换

分数融合： 权重设置 - 通过abtest得到 



第二版： mmoe

![image-20210203172046180](https://i.loli.net/2021/02/04/16EJ7Q4CgpvsAmT.png)





## Unbias LTR 

主要解决 训练数据中（用户的点击日志）的噪声： Position bias （因为样本排序靠前引起的点击 即位置对他的加权）

有以下两个思路：

- 降低 TOP 位置的样本权重   置信度不高  对不同位置有不同的权重--------没有收益
- 对 Position Bias 进⾏行行建模  



主要是第二种方法：

![image-20210203172753826](https://i.loli.net/2021/02/04/5KhdluIeYPSaC6z.png)

只有点击目标有 position bias 点击之后的 关注 收藏等目标与位置就无关了 



## Context Aware

**Point wise or pair wise or list wise** ？  

Point wise: 每次对单个文档进行打分， 比较所有候选item的打分来排序

pair wise: 每次对两个文档打分，预测两者的相对顺序， 一旦两两item都有序，则整体有序

list wise: 对list整体进行排序



如何做list wise：

![image-20210204081747704](https://i.loli.net/2021/02/04/BMsk7ReQHIc52Yb.png)

list size中间有采样？ 后续又经过了rerank阶段 

SE block？ SErank 学习特征在不不同 Context 下的特征重要性  

Wang, RuiXing, et al. "SERank: Optimize Sequencewise Learning to Rank Using Squeeze-and-Excitation
Network." arXiv preprint arXiv:2006.04084 (2020)



## End2End

BERT 能不不能 end2end 的训练？  做了以下尝试：

- 尝试将bert预训练 的初始2-3层 加入LTR网络 ----------- 速度慢 离线收益不大
- 用bert 对query和doc的标题 做**聚向量的表征**  --------------上线收益不错 

![image-20210204085210760](https://i.loli.net/2021/02/04/Z4tHCihMUwGAJDl.png)

## Session Aware

利用用户的近期交互信息  

bert向量加入模型 ， 与当前文档的embedding 做内积 最大匹配 （点积相乘取最大 尝试过attention之类的 并不work）



![image-20210204085319096](https://i.loli.net/2021/02/04/1rQk2pBDcI8ZzOP.png)



## GBDT特征编码-未上线

- GBDT 模型自动进行特征分桶和特征组合  
- 将 GBDT 输出的叶子节点编号作为category 特征喂给 NN 模型  



## 未来方向

- Online learning - 提高模型更新频率
- Graph embedding  
- 个性化  - 近期交互行为 
- 边缘计算 

