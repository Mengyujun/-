# 多目标排序在快手短视频推荐中的实践

来自 快手社区科学部-郑东-datafuntalk年终大会

分享大纲： 

![image-20210127093417690](https://i.loli.net/2021/01/27/KdD29XFjLx5I34l.png)



## 快手短视频推荐场景介绍

主要有3个页面： 

首页-发现频道（双列选择）

同城页面

首页精选（单列沉浸式）



### 短视频推荐的优化目标

核心指标： DAU （日活： 每日活跃用户数）

![image-20210127093933062](https://i.loli.net/2021/01/27/hS5cjHKEkvPmUzM.png)

上图显示了： 用户留存和 DAU的关系， 留存时间越长，DAU越高 因此可以通过 **提升使用时长/正向反馈 降低负反馈**来提高留存



用户留存的正负反馈指标：

- 隐式正反馈
  - 播放时长 有效播放 （播放完成度在75%以上（不确定比例）算一个有效播放） 播放完成率 复播等 
- 显示正反馈
  - 点赞 收藏 下载 进入个人页面 关注 正向评论 观看评论 原声点击 标签点击 分享 等主动操作
- 隐式负反馈
  - 短播放 以及 终止session
- 显示负反馈
  - 不感兴趣 举报 负向评论



## 多任务学习 从share bottom 到门控网络



个性化门控+多域门控融合：

![image-20210127103035821](https://i.loli.net/2021/01/27/JL2MVuOn7m3l94D.png)



![image-20210127103429066](https://i.loli.net/2021/01/27/BlnxVoQ9f8EbU4Y.png)



因为share-bottom 当目标之间存在较大差异无法学到最优  在MMOE的基础上进行改进 

**MMOE+特征/Embedding 对齐 + 行为序列建模**

![image-20210127163734456](https://i.loli.net/2021/01/27/F7rvKHf1Wg52XcN.png)



![image-20210127163829032](https://i.loli.net/2021/01/27/XGeA9RU3Sk8ohZO.png)



## 多目标精排： 手工融合到learn to rank

由**多任务学习**过渡到**多目标排序**： 

- 快手推荐追求**时长、点赞、关注、分享**等多种目标  
- 合适的排序目标和机制设计，获得多目标的协同提升   



stage1： 手动公式融合

缺点
• 过于依赖规则设计
• 过于依赖人工调参，维护成本高
• 固定权重，缺少个性化、场景化  



stage2： 树模型规则ensemble融合 

缺点：表达能力有限，无法online learning  



stage4： 端到端 learn to rank 

![image-20210129105543928](https://i.loli.net/2021/01/29/w9QTRi7FB4uLexg.png)



## 复杂多目标Ensemble Sort和在线自动调参  

存在很多复杂场景 中有不同的打分逻辑，

**常规融合：线性加权**
Score = a*scoreA + b * scoreB + c * ScoreC + … + m * ScoreM
**存在问题**：
• 不同Score之间**含义、量级和分布**差异较大
• 显式反馈如点赞率等在不同用户间差异巨大，难以适应统一权重
• 依赖模型预估值绝对大小，预估值分布变化时需重新调节或校准  



**优化方法：**

• 各子项分内做**Normalize**，如转换为序的函数，与GAUC目标一致 𝑆𝑐𝑜𝑟𝑒 =𝐶# = 𝑓(𝑟𝑎𝑛𝑘 𝑜𝑓 𝑆𝑐𝑜𝑟𝑒𝐶#)  --- **将排序转化为分数** 转化为同一量纲，这种排序同时和GAUC的预估值一致，与线上效果一致 

• 可兼容含义差异巨大的子项分，各子项目分权重可在同一量级调节
• 隐式反馈权重在不同用户上做到了某种自适应调节  （）



### 手动调参

**优点**：

简单轻量， 可解释性好

**缺点** 
• 效率低
• 依赖工程师经验
• 参数变多后，很难全局调优
• 处理能力有限，难以个性化、场景化  



### 离线learn2Rank：

优点：
• 可看作off-policy，数据利用率高（100%）
• 模型自由度高，可训练千亿参数规模  

缺点：
• 无法直接对标业务指标
• 难以考虑到线上复杂多模块的完整影响
• 存在训练数据和在线数据不一致性  



### 在线自动调参

![image-20210129111528920](https://i.loli.net/2021/01/29/NEaF3BcofrPzwTW.png)



  **探索与利用**（如何设置实验）
• 5%线上流量探索，每次探索N组参数
• 基线组每轮收集固定数量样本，探索组和基线组同始终  

**Reward设计**（对每组实验参数如何评价好坏）
• 每组参数时长和互动相比基线的相对涨跌幅来衡量
• 收益项：视频观看时长/个人页时长/评论区时长
• 约束项：互动，如播放/点赞/关注/分享/…，使用非线性约束
	• 阈值内，线性弱衰减
	• 超出阈值，指数强衰减  

**自动调参算法** （Cross-Entropy Method  ）

**CEM算法优点**
• 简洁、高效，超参很少
• 0阶方法，TopK选取只依赖reward的序，不需要对reward的数值进行建模，对噪声更加鲁棒
• 参数通过高斯分布扰动探索，线上指标相对平稳  

![image-20210129112749993](https://i.loli.net/2021/01/29/XdlqMcfu24ag1DH.png)

噪声来源
• 数据稀缺：5%探索流量分100组，每组参数仅仅相当于线上1/2000的流量
• 稀疏label：越稀疏的label噪声越大
• 指标随时间周期变化  



## 重排序- Listwise、强化学习和端上Rerank  

主要考虑视频之间的相互影响

### Listwise重排

方案设计
• **Top6 Rerank**: 对一个PageSize (6)的候选视频使用**Transformer**进行建模，刻画视频间相互影响
• 采用Weighted Logloss，学习目标类似Learn2Rank
• 前序视频对后序视频观看有影响，前后组合决定总收益  

![image-20210130163945431](https://i.loli.net/2021/01/30/xf9D7QskpnwS2Nb.png)



### 强化学习Rerank



### 端上Rerank

方案：
• 用户一次请求下发更多视频到客户端，如从6提升到20
• 端上部署模型，根据用户最新行为反馈，每一滑实时从剩余候选集中选择最佳的  



**优势**
• 用户对当前视频的反馈，可以立刻影响Next-One推荐，不必等到PageSize(=6)再去服务端刷新
• 上下滑场景替换后序视频后，用户无感知
• 可以利用端上丰富的特征，包括一 些数据量大、隐私等不便于上传到云端的特征
• 端上实现了实时推荐，所以PageSize可以变大，降低对服务端的请求压力和资源消耗  



具体模型： 

![image-20210130165146962](https://i.loli.net/2021/01/30/r4SQ67YwWiecaE2.png)



## 总结和展望

![image-20210130165752709](https://i.loli.net/2021/01/30/8D4rqibSM1XvaWL.png)